# RNN_GRU_LSTM_Example

This gives an example of using RNN, GRU and LSTM recurrent architectures in PyTorch. When compared to the vanilla RNN, GRU has two gates: update gate and reset (relevance) gate, and LSTM has three gates: input (update) gate, forget gate and output gate.  These 3 recurrent architectures are implemented in this example in such as way that one can use one of them at a time as well as learn what their relations and differences are when using them.
